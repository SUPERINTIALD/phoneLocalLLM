# phoneLLM

Run Local LLMs on Your Phone or Home Server

---

**phoneLLM** lets you run large language models (LLMs) on your own hardware—whether that's your phone, a home server, or another device. Take control of your data and privacy by keeping everything local.

## Features

- **Private & Secure**: Your data stays on your devices.
- **Flexible Deployment**: Use Ollama or LM Studio to launch your own LLM server.
- **Remote Access**: Connect securely from anywhere using Tailscale.
- **Customizable**: Integrate your own APIs for advanced features (with optional security trade-offs).

## Getting Started

1. **Set up an LLM server**  
    Install and run Ollama or LM Studio on your device.

2. **Connect your devices**  
    Use Tailscale to securely access your server from anywhere.

3. **Monitor and interact**  
    Privately monitor your activities and interact with your LLM.

## Coming Soon

- MCP integration
- Agentic AI features
- Easy API updates from chatGPT or other LLMs such as Perplexity, Grok, Gemini

---

*Make AI work for you—privately and securely!*
